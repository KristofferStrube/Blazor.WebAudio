@page "/AnalyzeMediaStream"
@using KristofferStrube.Blazor.MediaCaptureStreams
@using KristofferStrube.Blazor.WebIDL
@using KristofferStrube.Blazor.WebIDL.Exceptions
@implements IAsyncDisposable
@inject IJSRuntime JSRuntime
@inject IMediaDevicesService MediaDevicesService
<PageTitle>WebAudio - Analyze MediaStream</PageTitle>
<h2>Analyze MediaStream</h2>

<p>
    On this page we open a MediaStream using the <a href="https://github.com/KristofferStrube/Blazor.MediaCaptureStreams">Blazor.MediaCaptureStreams</a> library
    and construct a <code>MediaStreamAudioSourceNode</code> from this. We then feed it to an <code>AnalyzerNode</code> and plot graphs from its output.
</p>

@if (error is { } errorMessage)
{
    <p style="color: red;">@errorMessage</p>
}
else if (mediaStream is null)
{
    <button class="btn btn-primary" @onclick="OpenAudio">Load Audio</button>
}
else
{
    <h3>Time Domain Data</h3>
    <Plot Data="timeDomainMeasurements" />
    <h3>Frequency Data</h3>
    <span>Peak frequency: @Math.Round(peakFrequency, 0) Hz</span>
    <Plot Data="frequencyMeasurements" />
    <h3>Amplitude Data</h3>
    <AmplitudePlot Analyser="analyser" />

    @if (audioOptions.Count > 0)
    {
        <label for="audioSource">Audio Source</label>
        <select id="audioSource" @bind=selectedAudioSource @bind:after="OpenAudio">
            @foreach (var option in audioOptions)
            {
                <option value="@option.id" selected="@(option.id == selectedAudioSource)">@option.label</option>
            }
        </select>
    }
}

@code {
    private AudioContext? context;
    private AnalyserNode? analyser;
    private MediaDevices? mediaDevices;
    private string? error;
    private byte[] timeDomainMeasurements = Array.Empty<byte>();
    private byte[] frequencyMeasurements = Array.Empty<byte>();
    private bool makeMeasurements = false;
    private MediaStream? mediaStream;
    private List<(string label, string id)> audioOptions = new();
    private string? selectedAudioSource;
    private double peakFrequency = 0;

    async Task OpenAudio()
    {
        await StopAudioTrack();

        try
        {
            if (context is null)
            {
                context = await AudioContext.CreateAsync(JSRuntime);
            }
            if (mediaDevices is null)
            {
                mediaDevices = await MediaDevicesService.GetMediaDevicesAsync();
            }

            MediaTrackConstraints mediaTrackConstraints = new MediaTrackConstraints
                {
                    EchoCancellation = true,
                    NoiseSuppression = true,
                    AutoGainControl = false,
                    DeviceId = selectedAudioSource is null ? null : new ConstrainDomString(selectedAudioSource)
                };
            mediaStream = await mediaDevices.GetUserMediaAsync(new MediaStreamConstraints() { Audio = mediaTrackConstraints });

            var deviceInfos = await mediaDevices.EnumerateDevicesAsync();
            audioOptions.Clear();
            foreach (var device in deviceInfos)
            {
                if (await device.GetKindAsync() is MediaDeviceKind.AudioInput)
                {
                    audioOptions.Add((await device.GetLabelAsync(), await device.GetDeviceIdAsync()));
                }
            }

            analyser = await context.CreateAnalyserAsync();
            await using MediaStreamAudioSourceNode mediaStreamAudioSourceNode = await context.CreateMediaStreamSourceAsync(mediaStream);
            await mediaStreamAudioSourceNode.ConnectAsync(analyser);

            await Task.Delay(500);

            int bufferLength = (int)await analyser.GetFrequencyBinCountAsync();
            var timeDomainDataArray = await Uint8Array.CreateAsync(JSRuntime, bufferLength);
            var frequencyDataArray = await Uint8Array.CreateAsync(JSRuntime, bufferLength);

            var sampleRate = await context.GetSampleRateAsync();
            var fftSize = await analyser.GetFftSizeAsync();

            makeMeasurements = true;
            while (makeMeasurements)
            {
                await analyser.GetByteTimeDomainDataAsync(timeDomainDataArray);
                await analyser.GetByteFrequencyDataAsync(frequencyDataArray);

                timeDomainMeasurements = await timeDomainDataArray.GetAsArrayAsync();
                frequencyMeasurements = await frequencyDataArray.GetAsArrayAsync();

                var largestFrequencyIndex = frequencyMeasurements.ToList().IndexOf(frequencyMeasurements.Max());
                peakFrequency = largestFrequencyIndex * sampleRate / fftSize;

                await Task.Delay(1);
                StateHasChanged();
            }
        }
        catch (WebIDLException ex)
        {
            error = $"{ex.GetType().Name}: {ex.Message}";
        }
        catch (Exception ex)
        {
            error = $"An unexpected error of type '{ex.GetType().Name}' happened.";
        }
        StateHasChanged();
    }

    async Task StopAudioTrack()
    {
        makeMeasurements = false;
        if (mediaStream is null) return;
        var audioTrack = (await mediaStream.GetAudioTracksAsync()).FirstOrDefault();
        if (audioTrack is not null)
        {
            await audioTrack.StopAsync();
        }
        if (analyser is not null)
        {
            await analyser.DisposeAsync();
        }
    }

    public async ValueTask DisposeAsync()
    {
        await StopAudioTrack();
    }
}


